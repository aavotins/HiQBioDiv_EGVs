# Raw geodata {#Ch04}

This chapter describes raw geodata used and the preliminary processing conducted on them.

## State Forest Service's State Forest Registry {#Ch04.01}

krā

## Rural Support Service's information on declared fields {#Ch04.02}

krā

## Melioration Cadaster {#Ch04.03}

krā

## TopographicMap {#Ch04.04}

krā


## Corine Land Cover 2018 {#Ch04.05}

krā


## Publicly available LVM data {#Ch04.06}

krā


## Soil data {#Ch04.07}

Directory `Geodata/2024/Soils/` contains various soil related datasets that need 
to be combined (soil texture) or can be used individually (soil chemistry). These 
datasets and their location in the filetree are documented in following subchapters.

### Soil chemistry {#Ch04.07.01}

Data on soil chemistry are obtained from [European Soil Data Centre's](https://esdac.jrc.ec.europa.eu/) European 
Soil database [@esdac2]. Dataset decribing soil chemistry is derived from [LUCAS 
2009/2012 topsoil data](https://esdac.jrc.ec.europa.eu/content/chemical-properties-european-scale-based-lucas-topsoil-data). There are several chemical properties available with 
download, however not all of them are experts chosen for SDM, therefore not used 
further in this work:

- "P": used;

- "N": used;

- "K": used;

- "CEC": not used;

- "CN": used;

- "pH_CaCl": not used;

- "ph_H2o_ration_ph_CaCl": not used;

- "pH_H2O": used;

- "CaCO3": used.

Files were downloaded to `Geodata/2024/Soils/ESDAC/chemistry/` and no preprocessing 
was carried out.

### Soil texture Europe {#Ch04.07.02}

Data on soil texture are obtained from [European Soil Data Centre's](https://esdac.jrc.ec.europa.eu/) European 
Soil database [@esdac2]. Dataset is available as [European Soil Database v2 Raster Library 1kmx1km](https://esdac.jrc.ec.europa.eu/content/european-soil-database-v2-raster-library-1kmx1km). There 
are several properties available with download, `TXT` was used to 
create [soil texture product](#Ch05.02). Files were downloaded to `eodata/2024/Soils/ESDAC/texture/`. 

During the preprocessing (code below) layer was 
projected to match 10 m template with "near" as interpolation method, value `0` 
substituted with `NA` and masked and cropped to template. Result was saved for further 
processing.

```{r, eval=FALSE}
# libs ----
if(!require(terra)) {install.packages("terra"); require(terra)}
if(!require(sf)) {install.packages("sf"); require(sf)}
if(!require(tidyverse)) {install.packages("tidyverse"); require(tidyverse)}

# Template ----
template10=rast("./Templates/TemplateRasters/LV10m_10km.tif")

# ESDAC texture ----

sdTEXT=rast("./Geodata/2024/Soils/ESDAC/texture/SoilDatabaseV2_raster/ESDB-Raster-Library-1k-GeoTIFF-20240507/TEXT/TEXT.tif")
plot(sdTEXT)

sdTEXT=project(sdTEXT,template10,method="near")
plot(sdTEXT)

sdTEXT=subst(sdTEXT,0,NA)
plot(sdTEXT)

sdTEXT2=mask(sdTEXT,template10,
             filename="./RasterGrids_10m/2024/SoilTXT_ESDAC.tif",
             overwrite=TRUE)
plot(sdTEXT2)

```



### Soil texture LIZ {#Ch04.07.03}

Topsoil characteristics in Latvia were mapped in the mid-20th century, almost 
exclusively in farmlands. With time, data were digitised and combined with some 
other information creating artefacts. Therefore preprocessing was necessary. The 
version we used was obtained form project "GOODWATER" C1D1_Deliverable_R2.

File is stored at `Geodata/2024/Soils/TopSoil_LV/`.

Preprocessing included:

- reclassification:

    - we coded as `clay` (3) following labels from field `GrSast` - "M","M1","Mp","M2","sM1","sMp1";
    
    - we coded as `silt` (2) following labels from field `GrSast` - "sM", "sMp", "M2", "sM2", "sMp2", "sM3", "sMp3";

    - we coded as `sand` (1) following labels from field `GrSast` - "mS", "mSp", "S", "sS", "iS", "Gr", "mGr", "D";
    
    - we coded as `organic` (4) following labels from field `GrSast` - "l", "vd", "vj", "n","T";
    
    - left others as unclassified.
    
- coordinate transformation to epsg:3059;

- invsestigated resulting layer looking for anomalies by scrolling in interactive 
GIS. Investigations led to exclusion of land parcels from 200 ha.

- rasterization to 10 m template with highest class code prevailing.


```{r,eval=FALSE}
# libs ----
if(!require(terra)) {install.packages("terra"); require(terra)}
if(!require(sf)) {install.packages("sf"); require(sf)}
if(!require(tidyverse)) {install.packages("tidyverse"); require(tidyverse)}

# Template ----
template10=rast("./Templates/TemplateRasters/LV10m_10km.tif")

# Farmland soil texture ----

augsnes=st_read("./Geodata/2024/Soils/TopSoil_LV/soil.gpkg",layer="soilunion")

# calculate parcels area
augsnes$platiba_ha=as.numeric(st_area(augsnes))/10000

# only parcels with existing information on texture
tuksas=augsnes %>% 
  filter(GrSast=="")

# classification
clay=c("M","M1","Mp","M2","sM1","sMp1")
silt=c("sM", "sMp", "M2", "sM2", "sMp2", "sM3", "sMp3")
sand=c("mS", "mSp", "S", "sS", "iS", "Gr", "mGr", "D")
peat=c("l", "vd", "vj", "n","T")
augsnes=augsnes %>% 
  mutate(grupas=case_when(GrSast %in% sand~"Sand",
                          GrSast %in% silt~"Silt",
                          GrSast %in% clay~"Clay",
                          GrSast %in% peat~"organika",
                          .default=NA)) %>% 
  mutate(grupas_num=case_when(GrSast %in% sand~"1",
                              GrSast %in% silt~"2",
                              GrSast %in% clay~"3",
                              GrSast %in% peat~"4",
                              .default=NA))

# crs
augsnes_3059=st_transform(augsnes,crs=3059)

# only existing texture classification
augsnes_3059=augsnes_3059 %>% 
  filter(!is.na(grupas_num))

# parcels up to 200 ha
augsnes_3059small=augsnes_3059 %>% 
  filter(!is.na(grupas_num)) %>% 
  filter(platiba_ha<200)

# rasterization
virsaugsnem2=rasterize(augsnes_3059small,template10,field="grupas_num",fun="max",
                       filename="./RasterGrids_10m/2024/SoilTXT_topSoilLV.tif",
                       overwrite=TRUE)
plot(virsaugsnem2)

```


### Soil texture Quaternary {#Ch04.07.04}

Data on Quaternary Geology are digitised and stored by University of Latvia 
Geology group.

File is stored at `Geodata/2024/Soils/QuaternaryGeology_LV/`.

Preprocessing included:

- reclassification:

    - we coded as `sand` (1) following values from field `Litologija` - "smilts", "smilts_aleiritiska", 
    "smilts_dunjaina", "smilts_grants", "smilts_grants_oli", "smilts_grants_oli_aleirits", "smilts_kudraina", 
    "smilts_videjgraudaina, malsmilts", "smilts_videjgraudaina"~"Sand";
    
    - we coded as `silt` (2) following values from field `Litologija` - "aleirits", "aleirits_malains",
    "morena", "smilts_aleirits_mals", "smilts_aleirits_sapropelis", "smilts_malaina_dazadgraudaina, malsmilts";
    
    - we coded as `clay` (3) following values from field `Litologija` - "mals", "mals_aleiritisks";
    
    - we coded as `organic` (4) following values from field `Litologija` - "dunjas", "kudra";

- coordinate transformation to epsg:3059;

- rasterization to 10 m template with highest class code prevailing.


```{r, eval=FALSE}
# libs ----
if(!require(terra)) {install.packages("terra"); require(terra)}
if(!require(sf)) {install.packages("sf"); require(sf)}
if(!require(tidyverse)) {install.packages("tidyverse"); require(tidyverse)}

# Template ----
template10=rast("./Templates/TemplateRasters/LV10m_10km.tif")

# Quarternary geology ----

kvartars=sfarrow::st_read_parquet("./Geodata/2024/Soils/QuaternaryGeology_LV/Kvartargeologija.parquet")

# reclassification
kvartars=kvartars %>% 
  mutate(grupas = case_when(Litologija=="aleirits"~"Silt",
                            Litologija=="aleirits_malains"~"Silt",
                            Litologija=="dunjas"~"organika",
                            Litologija=="kudra"~"organika",
                            Litologija=="mals"~"Clay",
                            Litologija=="mals_aleiritisks"~"Clay",
                            Litologija=="morena"~"Silt",
                            Litologija=="smilts"~"Sand",
                            Litologija=="smilts_aleiritiska"~"Sand",
                            Litologija=="smilts_aleirits_mals"~"Silt",
                            Litologija=="smilts_aleirits_sapropelis"~"Silt",
                            Litologija=="smilts_dunjaina"~"Sand",
                            Litologija=="smilts_grants"~"Sand",
                            Litologija=="smilts_grants_oli"~"Sand",
                            Litologija=="smilts_grants_oli_aleirits"~"Sand",
                            Litologija=="smilts_kudraina"~"Sand",
                            Litologija=="smilts_malaina_dazadgraudaina, malsmilts"~"Silt",
                            Litologija=="smilts_videjgraudaina, malsmilts"~"Sand",
                            Litologija=="smilts_videjgraudaina"~"Sand",
                            .default=NA))
# numeric codes
kvartars=kvartars %>% 
  mutate(grupas_num=case_when(grupas == "Sand" ~"1",
                              grupas == "Silt" ~"2",
                              grupas == "Clay" ~"3",
                              grupas == "organika" ~"4",
                              .default=NA))

# crs transformation
kvartars_3059=st_transform(kvartars,crs=3059)

# nonmissing classes
kvartars_3059=kvartars_3059 %>% 
  filter(!is.na(grupas_num))

# rasterization
apaksaugsnem=rasterize(kvartars_3059,template10,field="grupas_num",fun="max",
                       filename="./RasterGrids_10m/2024/SoilTXT_QuarternaryLV.tif",
                       overwrite=TRUE)
plot(apaksaugsnem)

```



### Organic soils SILAVA {#Ch04.07.05}

The distribution of organic soils was modelled by EU LIFE Programme project 
"Demonstration of climate change mitigation potential of nutrients rich organic 
soils in Baltic States and Finland" at the scientific institue SILAVA. Results are 
available from their web service: https://silava.forestradar.com/geoserver/silava

Downloaded file was stored at `Geodata/2024/Soils/OrganicSoils_SILAVA/`.

Even tough the layer covers whole of Latvia, it has visible inconsistencies, 
particularly stripes. These were drawn manually (as vector polygons) and masked 
out as a part of preprocessing. 

For further soil texture analysis we saved a GeoTIFF file with only presences.

```{r,eval=FALSE}
# libs ----
if(!require(terra)) {install.packages("terra"); require(terra)}
if(!require(sf)) {install.packages("sf"); require(sf)}
if(!require(tidyverse)) {install.packages("tidyverse"); require(tidyverse)}

# Template ----
template10=rast("./Templates/TemplateRasters/LV10m_10km.tif")

# Organic Soils SILAVA ----

organika_silava=rast("./Geodata/2024/Soils/OrganicSoils_SILAVA/Silava_OrgSoils.tif")
plot(organika_silava)
# visible stripes

# only 40+ cm deep
organika_silava=ifel(organika_silava==2,1,NA)
organika_silavaLV=project(organika_silava,template10)

# stripes drawn manually, rasterization
silavas_telpai=st_read("./IevadesDati/Augsnes_COMB/KudraugsnuPrognozes_Silava/stripam.gpkg",
                       layer="stripam")
silavas_telpai=st_transform(silavas_telpai,crs=3059)
silavas_telpai$yes=1
SilavasTelpa_10=rasterize(silavas_telpai,template10,field="yes")

# presence-only layer without stripes
silava_BezStripam1=ifel(organika_silavaLV==1&SilavasTelpa_10==1,1,NA)
silava_BezStripam=mask(silava_BezStripam1,template10)
plot(silava_BezStripam)
writeRaster(silava_BezStripam,
            "./RasterGrids_10m/2024/SoilTXT_OrganicSilava.tif",
            overwrite=TRUE)

```


### Organic soils LU {#Ch04.07.06}

The distribution of organic soils in farmlands was modelled by the University of 
Latvia project "Improvement of sustainable soil resource management in agriculture".

From all the results we used layer `YN_prognozes_smooth.tif` stored 
at `Geodata/2024/Soils/OrganicSoils_LU/`.

Preprocessing consisted of projecting the layer to match 10 m template. Both presences 
and absences were saved for further processing.

```{r,eval=FALSE}
# libs ----
if(!require(terra)) {install.packages("terra"); require(terra)}
if(!require(sf)) {install.packages("sf"); require(sf)}
if(!require(tidyverse)) {install.packages("tidyverse"); require(tidyverse)}

# Template ----
template10=rast("./Templates/TemplateRasters/LV10m_10km.tif")

# Organic Soils LU ----


kudra_norvegi=rast("./Geodata/2024/Soils/OrganicSoils_LU/YN_prognozes_smooth.tif")
kudra_norvLV=project(kudra_norvegi,template10)
plot(kudra_norvLV)

writeRaster(kudra_norvLV,
            "./RasterGrids_10m/2024/SoilTXT_OrganicLU.tif",
            overwrite=TRUE)


```




## Dynamic World data {#Ch04.08}

Dynamic World (DW) is a relatively new Earth observation system product that 
classifies land cover and land use (LULC) into nine categories (0=water, 1=trees, 
2=grass, 3=flooded_vegetation, 4=crops, 5=shrub_and_scrub, 6=built, 7=bare, 
8=snow_and_ice), for each ESA Copernicus Sentinel-2 image with identified 
cloudiness ≤35, allowing for filtering and various aggregations [@DynWorld].

DW input information - raster layer for each season in each year - prepared on 
the Google Earth Engine platform [@GEEpaper] using 
a [replication script](https://code.earthengine.google.com/0f9fd61ee41af11d218ce8692abebe9b). 
To use this script, you need a [GEE account and project](https://console.cloud.google.com/earth-engine/welcome) 
and sufficient space on Google Drive. When executing the command line, a download 
will be offered for a file covering the time period from the value in row 7 to 
the value in row 8 (the file name should be specified in row 32, its 
description in row 33 and the directory on Google Drive in row 31, or 
all of this can be specified by confirming the save). This script is not optimized 
for preparing all seasonal sections for all years, so in order to reproduce or 
expand this study, it is necessary to change it manually.

Downloaded files are to be stored at `Geodata/2024/DynamicWorld/RAW/`.

During download, it can be seen that each layer covering the whole of Latvia is 
divided into several sheets. This is because, in order to ensure a true zero 
class (class "water" rather than background), the layers are encoded as Float 
rather than integers. All of these tiles need to be downloaded, and the following 
R command lines combine them, ensuring that the coordinate system and pixels 
correspond to the reference raster.

```{r, eval=FALSE}
# libs ----
if(!require(terra)) {install.packages("terra"); require(terra)}
if(!require(tidyverse)) {install.packages("tidyverse"); require(tidyverse)}

# 10 m template ----
template10=rast("./Templates/TemplateRasters/LV10m_10km.tif")

# DW export no GEE ----
faili=data.frame(faili=list.files("./Geodata/2024/DynamicWorld/RAW/"))
faili$celi_sakums=paste0("./Geodata/2024/DynamicWorld/RAW/",faili$faili)

# Sagatavošana ----
faili=faili %>% 
  separate(faili,into=c("DW","gads","periods","parejais"),sep="_",remove = FALSE) %>% 
  mutate(unikalais=paste0(DW,"_",gads,"_",periods),
         mosaic_name=paste0(unikalais,".tif"),
         masaic_cels=paste0("./Geodata/2024/DynamicWorld/",mosaic_name))

# every layer consists of two tiles
unikalie=levels(factor(faili$unikalais))
min(table(faili$unikalais))
max(table(faili$unikalais))

# job
for(i in seq_along(unikalie)){
  unikalais=faili %>% filter(unikalais==unikalie[i])
  beigu_cels=unique(unikalais$masaic_cels)
  
  print(i)
  
  viens=rast(unikalais$celi_sakums[1])
  divi=rast(unikalais$celi_sakums[2])
  
  viens2=project(viens,template10)
  divi2=project(divi,template10)
  
  mozaika=mosaic(viens2,divi2,fun="first")
  maskets=mask(mozaika,template10,
               filename=beigu_cels,
               overwrite=TRUE)

  print(beigu_cels)
}

```


## The Global Forest Watch {#Ch04.09}

The Global Forest Watch (GFW) is a widely known product that describes tree 
canopy cover in 2000, its annual growth from 2001 to 2012, and its annual 
loss from 2001 to the current version, which is updated annually [@theGFW]. The 
data is available both on the [project website](https://data.globalforestwatch.org/documents/941f17325a494ed78c4817f9bb20f33a/explore) 
and on [GEE](https://developers.google.com/earth-engine/datasets/catalog/UMD_hansen_global_forest_change_2024_v1_12), where 
it was developed. This project uses v1.12, in which the last year of tree loss 
dating is 2024, preparing it for download on the GEE platform with 
this [replication script](https://code.earthengine.google.com/4a12b7504ceafe7f422dd7efbe804b67). 
To use this script, you need a [GEE account and project](https://console.cloud.google.com/earth-engine/welcome) 
and sufficient space on Google Drive. When executing the command lines, you will 
be offered to download the file, which you need to save to Google Drive.

After executing the command lines and preparing the results in Google Drive, 
four files are available for download. The location to download them is 
`Geodata/2024/Trees/GFW/RAW/`. After download, these files need to be projected 
to match the reference raster.


```{r, eval=FALSE}
# libs ----
if(!require(terra)) {install.packages("terra"); require(terra)}

# 10 m rastra template ----
template10=rast("./Templates/TemplateRasters/LV10m_10km.tif")

# TreeCoverLoss ----
treecoverloss=rast("./Geodata/2024/Trees/GFW/RAW/TreeCoverLoss_v1_12.tif")

tcl=ifel(treecoverloss<1,NA,treecoverloss)

tcl2=terra::project(tcl,paraugs)
tcl3=mask(tcl2,paraugs,filename="./Geodata/2024/Trees/GFW/TreeCoverLoss_v1_12.tif",overwrite=TRUE)

```


## Palsar {#Ch04.10}

The Palsar Forests resource is based on PALSAR-2 synthetic aperture radar (SAR) 
reflectance classification of forest and non-forest land with a pixel 
resolution of 25 m. Forests are classified as areas of at least 0.5 ha covered 
with trees, where tree cover (at least 5 m high) is at least 10% [@PALSARForest]. 
The data is available at [GEE](https://developers.google.com/earth-engine/datasets/catalog/JAXA_ALOS_PALSAR_YEARLY_FNF4). 
This project uses a 4-class version (1=Dense Forest, 2=Non-dense Forest, 
3=Non-Forest, 4=Water), in which the last tree cover dating year is 2020, 
prepared for download on the GEE platform with this 
[replication script](https://code.earthengine.google.com/3ec78ab057e6c8910cb1546002132b34). 
To use this script, you need a [GEE account and project](https://console.cloud.google.com/earth-engine/welcome) 
and sufficient space on Google Drive. When executing the command lines, you will 
be offered to download the file, which you need to save to Google Drive.

After executing the command lines and preparing the results in Google Drive, 
four files are available for download. The location to download them is 
`Geodata/2024/Trees/Palsar/RAW/`. After download, these files need to be projected 
to match the reference raster and merged. In this resource, trees are coded into 
two groups: 1=Dense Forest and 2=Non-dense Forest, which need to be merged and 
the rest converted to missing values (code below).

Although the data in this resource describes the situation in 2020 rather 
than 2024, it has been used because [The Global Forest Watch data](#Ch04.09) is 
available to describe the disappearance of tree canopy cover, but the appearance 
of canopy cover is not so rapid that there would be significant changes over a 
four-year period.

```{r, eval=FALSE}
# libs ----
if(!require(terra)) {install.packages("terra"); require(terra)}

# 10 m rastra template ----
template10=rast("./Templates/TemplateRasters/LV10m_10km.tif")


# PALSAR Forests ----

fnf1=rast("./Geodata/2024/Trees/Palsar/RAW/ForestNonForest-0000023296-0000023296.tif")
fnf2=rast("./Geodata/2024/Trees/Palsar/RAW/ForestNonForest-0000023296-0000000000.tif")
fnf3=rast("./Geodata/2024/Trees/Palsar/RAW/ForestNonForest-0000000000-0000023296.tif")
fnf4=rast("./Geodata/2024/Trees/Palsar/RAW/ForestNonForest-0000000000-0000000000.tif")

fnf1p=terra::project(fnf1,template10)
fnf2p=terra::project(fnf2,template10)
fnf3p=terra::project(fnf3,template10)
fnf4p=terra::project(fnf4,template10)

fnfA=terra::merge(fnf1p,fnf2p)
fnfB=terra::merge(fnfA,fnf3p)
fnfC=terra::merge(fnfB,fnf4p)
plot(fnfC)

fnf_X=ifel(fnfC<=2&fnfC>=1,1,NA)
plot(fnf_X)

fnf_XX=mask(fnf_X,template10,
            filename="./Geodata/2024/Trees/Palsar/Palsar_Forests.tif",
            overwrite=TRUE)
```



## CHELSA v2.1 {#Ch04.11}

Climatologies at high resolution for the Earth's land surface areas (CHELSA) is 
30 arc second global downscaled climate data set [@CHELSA]. The temperature algorithm 
is based on statistical downscaling of atmospheric temperatures. The precipitation 
algorithm incorporates orographic predictors including wind fields, valley 
exposition, and boundary layer height, with a subsequent bias correction. CHELSA 
climatological data has a similar accuracy as other products for temperature, but 
that its predictions of precipitation patterns are better [@CHELSA]. Data 
(1980-2010 baseline) are freely available for download 
from [homepage](https://chelsa-climate.org/) forwarding 
to download server, providing download links for selected products. There is also technical 
specification available, to decode layer names (https://chelsa-climate.org/wp-admin/download-page/CHELSA_tech_specification_V2.pdf).

The download links we used together with renaming scheme are [available](https://github.com/aavotins/HiQBioDiv_EGVs/blob/main/Data/Geodata/2024/CHELSA/CHELSAdownload_rename.csv) 
with this document. The following command lines perform download, crop to the 
extent of Latvia (using 1 km vector grid) and saves files for further processing 
described with other [EGVs](#Ch06).

```{r, eval=FALSE}
# libs ----
if(!require(terra)) {install.packages("terra"); require(terra)}
if(!require(sf)) {install.packages("sf"); require(sf)}
if(!require(sfarrow)) {install.packages("sfarrow"); require(sfarrow)}
if(!require(tidyverse)) {install.packages("tidyverse"); require(tidyverse)}
if(!require(curl)) {install.packages("curl"); require(curl)}

# templates ----
# 1km grid
tikls1km=sfarrow::st_read_parquet("./Templates/TemplateGrids/tikls1km_sauzeme.parquet")
telpai=tikls1km %>% 
  mutate(yes=1) %>% 
  summarise(yes=max(yes)) %>% 
  st_buffer(.,dist=10000)

# download and crop ----

links_names=read_csv("./Geodata/2024/CHELSA/CHELSAdownload_rename.csv")
links_names=links_names %>% 
  filter(todownload==1)

for(i in seq_along(links_names$localname)){
  print(i)
  sakums=Sys.time()
  links=links_names$weblocation[i]
  saving1="./Geodata/2024/CHELSA/draza.tif"
  saving2=paste0("./Geodata/2024/CHELSA/",links_names$localname[i])
  
  curl_download(url=links,destfile = saving1,quiet = FALSE)
  fails=rast(saving1)
  telpa=st_transform(telpai,crs=st_crs(fails))
  nogriezts=crop(fails,telpa,
                 filename=saving2,
                 overwrite=TRUE)
  unlink(saving1)
  beigas=Sys.time()
  ilgums=beigas-sakums
  print(ilgums)
}

```




## HydroClim data {#Ch04.12}

HydroClim is a near-global freshwater-specific environmental variable dataset, 
created for biodiversity analysis at 1 km resolution [@HydroClim]. Dataset 
contains many different variables along the HydroSHEDS river 
network [@HydroSheds], including upstream climate recalculated from 
worldclim [@worldclim_hijmans]. We downloaded (to `Geodata/2024/HydroClim/`) 
averaged upstream climate from [Zenodo repository](https://zenodo.org/records/5089529) 
(available also from [Dryad](https://datadryad.org/dataset/doi:10.5061/dryad.dv920)) 
and cropped to the extent of Latvia and renamed files for further processing 
with the code below. Renaming scheme is [published with document](https://github.com/aavotins/HiQBioDiv_EGVs/blob/main/Data/Geodata/2024/HydroClim/HydroClim_renaming.csv)

```{r,eval=FALSE}
# libs ----
if(!require(terra)) {install.packages("terra"); require(terra)}
if(!require(sf)) {install.packages("sf"); require(sf)}
if(!require(sfarrow)) {install.packages("sfarrow"); require(sfarrow)}
if(!require(tidyverse)) {install.packages("tidyverse"); require(tidyverse)}

# templates ----

template100=rast("./Templates/TemplateRasters/LV100m_10km.tif")
tikls1km=sfarrow::st_read_parquet("./Templates/TemplateGrids/tikls1km_sauzeme.parquet")

# reading HydroClim ----
videjie=terra::rast("./Geodata/2024/HydroClim/hydroclim_average+sum.nc")

# reading dictionary -----
slanu_nosaukumi=read_csv("./Geodata/2024/HydroClim/HydroClim_renaming.csv")

# cropping ---
tikls1km_reproj=st_transform(tikls1km,crs=st_crs(videjie))
telpai=tikls1km %>% 
  mutate(yes=1) %>% 
  summarise(yes=max(yes)) %>% 
  st_buffer(.,dist=10000) %>% 
  st_transform(.,crs=st_crs(videjie))
videjie=terra::crop(videjie,telpai)

# layer names ----
names(videjie)=slanu_nosaukumi$local_name

# saving files ----
for(i in seq_along(slanu_nosaukumi$local_name)){
  nosaukumam=slanu_nosaukumi$local_name[i]
  writeRaster(videjie[[i]],
              paste0("./Geodata/2024/HydroClim/",nosaukumam),
              overwrite=TRUE)
}

```

The raster dataset contains values only where large enough rivers are detected 
in HydroSHEDS. However, for species distribution modelling in this project 
we need continuously covered raster surfaces. For necessary geoprocessing to create such surfaces, we downloaded also HydroBASINS [@HydroBasins] [dataset](https://www.hydrosheds.org/products/hydrobasins) to `Geodata/2024/HydroClim/`. 
These procedures were EGV-specific and are described with other [EGVs](#Ch06).

## Sentinel-2 indices {#Ch04.13}

The European Space Agency (ESA) Copernicus program's Sentinel-2 mission is a 
constellation of two (three since 09/05/2024) identical satellites orbiting in 
the same orbit. The first satellite, Sentinel-2A, entered its orbit and 
underwent calibration tests on 2015-06-23, the second (Sentinel-2B) on 2017-03-07, 
with the first images available earlier. Each satellite captures high-resolution 
images (from 10 m (at the equator) pixel resolution) in 13 spectral channels 
with a return time of up to 5 days (more frequently closer to the poles) (https://www.esa.int/Applications/Observing_the_Earth/Copernicus/Sentinel-2). The 
data from this mission is freely available, including on the Google Earth Engine 
platform [@GEEpaper] for various large-scale pre-processing and analysis. We use 
the harmonized Level-2A (https://developers.google.com/earth-engine/datasets/catalog/COPERNICUS_S2_SR_HARMONIZED#description) product, applying a cloud mask that includes not only cloud filtering but also 
shadow filtering, so that for each filtered (cloud and seasonal - from April to 
October and from 2020 to 2024) to calculate the normalized difference vegetation 
index (NDVI), the normalized difference moisture index (NDMI), and the 
normalized difference water index (NDWI) as well as various metrics. 
A [replication script](https://code.earthengine.google.com/78024b3354cccb526159fd865b214771) 
can be used to prepare the data. To use this script, 
you need a [GEE account and project](https://console.cloud.google.com/earth-engine/welcome) 
and sufficient space on Google Drive. When executing the command lines, the 
following files will be offered for download:

- `NDVI_median-ST-[runtag, 20250820 by default]` - NDVI short-term median (2020-2024) of annual medians (April to October)

- `NDVI_p25-ST-[runtag, 20250820 by default]` - NDVI short-term median (2020-2024) of annual 25th percentiles (April to October)

- `NDVI_p75-ST-[runtag, 20250820 by default]`- NDVI short-term median (2020-2024) of annual 75th percentiles (April to October)

- `NDVI_iqr-ST-[runtag, 20250820 by default]` - NDVI short-term median (2020-2024) of inter-quartile ranges (April to October)

- `NDVI_median-LY-[runtag, 20250820 by default]` - NDVI last-years (2024) median (April to October)

- `NDMI_median-ST-[runtag, 20250820 by default]` - NDMI short-term median (2020-2024) of annual medians (April to October)

- `NDMI_p25-ST-[runtag, 20250820 by default]` - NDMI short-term median (2020-2024) of annual 25th percentiles (April to October)

- `NDMI_p75-ST-[runtag, 20250820 by default]` - NDMI short-term median (2020-2024) of annual 75th percentiles (April to October)

- `NDMI_iqr-ST-[runtag, 20250820 by default]` - NDMI short-term median (2020-2024) of inter-quartile ranges (April to October)

- `NDMI_median-LY-[runtag, 20250820 by default]` - NDMI last-years (2024) median (April to October)

- `NDWI_median-ST-[runtag, 20250820 by default]` - NDMI short-term median (2020-2024) of annual medians (April to October)

- `NDWI_p25-ST-[runtag, 20250820 by default]` - NDWI short-term median (2020-2024) of annual 25th percentiles (April to October)

- `NDWI_p75-ST-[runtag, 20250820 by default]` - NDWI short-term median (2020-2024) of annual 75th percentiles (April to October)

- `NDWI_iqr-ST-[runtag, 20250820 by default]` - NDWI short-term median (2020-2024) of inter-quartile ranges (April to October)

- `NDWI_median-LY-[runtag, 20250820 by default]` - NDWI last-years (2024) median (April to October)

After executing the command line and preparing the results in Google Drive, it 
can be seen that each layer covering the whole of Latvia is divided into 
several tiles. This is because the layers are encoded as Float and exceed 4 GB 
in size before GeoTIFF compression. All of these files need to be downloaded and 
located at `Geodata/2024/S2indices/RAW`. The following R commands combine them, 
ensuring the coordinate systems and its naming, and pixels match the reference 
raster, while renaming files to ``EO_[index]-[term: ST or LY][statistic]``.

```{r,eval=FALSE}

# libs ----
if(!require(terra)) {install.packages("terra"); require(terra)}
if(!require(tidyverse)) {install.packages("tidyverse"); require(tidyverse)}


# 10 m raster template ----
template10=rast("./Templates/TemplateRasters/LV10m_10km.tif")

# Fails as exported from GEE ----
faili=data.frame(fails=list.files("./Geodata/2024/S2indices/RAW/",pattern = ".tif"))
faili$celi_sakums=paste0("./Geodata/2024/S2indices/RAW/",faili$fails)


# file names ----
faili=faili %>% 
  separate(fails,into=c("nosaukums","vidus","beigas"),sep="-",remove = FALSE) %>% 
  mutate(mosaic_name=paste0("EO_",nosaukums,"-",beigas,tolower(vidus),".tif"),
         masaic_cels=paste0("./Geodata/2024/S2indices/Mosaics/",mosaic_name))


unikalie=levels(factor(faili$mosaic_name))
min(table(faili$mosaic_name))
max(table(faili$mosaic_name))

# preparation of mosaics ----
for(i in seq_along(unikalie)){
  sakums=Sys.time()
  unikalais=faili %>% filter(mosaic_name==unikalie[i])
  beigu_cels=unique(unikalais$masaic_cels)
  
  print(i)
  
  # there are exactly 2 tiles per file
  viens=rast(unikalais$celi_sakums[1])
  divi=rast(unikalais$celi_sakums[2])
  
  viens2=terra::project(viens,template10)
  divi2=terra::project(divi,template10)
  
  mozaika=terra::merge(viens2,divi2)
  maskets=mask(mozaika,template10,
               filename=beigu_cels,overwrite=TRUE,
               gdal=c("COMPRESS=LZW","TILED=YES","BIGTIFF=IF_SAFER"),
               datatype="FLT4S",
               NAflag=NA)
  
  plot(maskets,main=unikalie[i])
  print(beigu_cels)
  beigas=Sys.time()
  ilgums=beigas-sakums
  print(ilgums)
}

```


## Waste and garbage disposal sites, landfills {#Ch04.14}

Information on landfills has been compiled from [VARAM](https://www.varam.gov.lv/sites/varam/files/content/files/atkritumu_poligoni_lv_karte.pdf) and 
Latvian Environment, Geology and Meteorology Center 
["Report on landfills in Latvia in 2023"](https://videscentrs.lvgmc.lv/files/Vide/Atkritumi_un_radiacijas_objekti/Nr_3_parskats_par_atkritumiem/3Atkritumi_kopsavilkums_2023.pdf) listed landfills and their addresses. The coordinates required 
for the preparation of EGVs were found by combining the 
resources https://www.google.com/maps and https://balticmaps.eu/. In addition to 
the resources mentioned above, an object was added at the address 
"Dardedzes C, Mārupes pag., Mārupes nov., Latvia, LV-2166".

In addition, information from the [State Environmental Service on 
separated waste and deposit packaging collection points](https://skiroviegli.lv/#/) 
was used, exporting it to an Excel file.

Both data sets were combined into a single file 
and [added](https://github.com/aavotins/HiQBioDiv_EGVs/blob/main/Data/Geodata/2024/GarbageWasteLandfills/Atkritumi.xlsx) to this material.


## Digital elevation/terrain models {#Ch04.15}

With the publication of continuous aerial laser scanning data for the territory of Latvia (https://www.lgia.gov.lv/lv/digitalie-augstuma-modeli-0), various 
high-resolution (1 m and higher) digital surface models (DSM) and 
digital elevation models (DEM) have been developed. Since the input data is the 
same in all cases, the values of these (corresponding) models are identical 
across almost the entire territory of the country. However, airborne laser 
scanning data (1) is not available for the entire territory of the country, 
and (2) there are differences between the models in terms of filling (availability 
of values) outside inland waters and (3) filling of water bodies themselves. 
However, for areas covered by data on land, the values are almost 
identical (Pearson's correlation coefficients between the DEMs developed 
by LU ĢZZF, LVMI Silava, and LĢIA are greater than 0.999999).

The arithmetic mean between the DEMs developed by LU ĢZZF and LVMI Silava, 
prepared in the University of Latvia project "Improvement of sustainable soil resource management 
in agriculture", was used as the base DEM. The resolution of this DEM is 1 m, 
which is not necessary for species distribution modeling input data, therefore 
the layer is designed to correspond to the reference 10 m raster.

When comparing the projected DEM with the reference, there are clearly 
distinguishable areas where there is no data. This has been solved by using 
the DEM with a resolution of 10 m developed by Māris Nartišs (LU ĢZZF) in 2018, 
which covers the entire territory of Latvia without gaps. To prevent sharp 
edges from forming in the fill areas (smooth transitions), an arithmetic mean 
layer was created, covering the entire territory of Latvia and matching the 
reference raster.

A slope layer has also been created from this raster, which is designed in 
accordance with the reference. The slope is expressed in degrees and calculated 
using the 8-neighbor approach. The same applies to the aspect or slope 
direction.

```{r,eval=FALSE}
# Libs ----



```



## Latvian Exclusive Economic Zone polygon {#Ch04.16}

The waters of Latvia's Exclusive Economic Zone were obtained from 
the [HELCOM map and data service](https://maps.helcom.fi/website/mapservice/?datasetID=ae58c373-674c-45d1-be0f-1ff69a59f9ba). After downloading, this line file was 
analogically connected to the coastline file obtained from the same resource.


## Nature Conservation Agency's data {#Ch04.17}

vai tiešām izmantoju?


